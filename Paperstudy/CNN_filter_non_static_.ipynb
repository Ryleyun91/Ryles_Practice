{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d35bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import preprocessing \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801adef",
   "metadata": {},
   "source": [
    "train = open('../DATA/cnnpaper/ratings_train.txt', 'r')\n",
    "train = train.readlines()\n",
    "test = open('../DATA/cnnpaper/ratings_test.txt', 'r')\n",
    "test = test.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939fe8f",
   "metadata": {},
   "source": [
    "train = [line.strip().split('\\t') for line in train]\n",
    "test = [line.strip().split('\\t') for line in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e2133a",
   "metadata": {},
   "source": [
    "train_df = pd.DataFrame(train[1:], columns=train[0])\n",
    "test_df = pd.DataFrame(test[1:], columns=test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9e3f4",
   "metadata": {},
   "source": [
    "spacing = Spacing()\n",
    "train_df['document'] = [spacing(str(sent)) for sent in train_df['document']]\n",
    "test_df['document'] = [spacing(str(sent)) for sent in test_df['document']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c6dfa",
   "metadata": {},
   "source": [
    "train_df.to_csv('train_spacing.csv')\n",
    "test_df.to_csv('test_spacing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24eddb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_dataset = pd.read_csv('../DATA/train_spacing.csv')\n",
    "test_dataset = pd.read_csv('../DATA/test_spacing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812e0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "289719d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 37.4 ms, total: 12 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def pos(x):\n",
    "    try:\n",
    "        text = ''\n",
    "        for word, pos in mecab.pos(str(x)):\n",
    "            if pos[0] not in ['J','I','E']:\n",
    "                if type(re.search(\"\\W+|[0-9]\", word))!=re.Match: \n",
    "                    # and len(word)!=1:\n",
    "                    text+=\" \"+word\n",
    "        return text.strip()\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "train_dataset[\"pos\"] = train_dataset[\"document\"].apply(pos)\n",
    "test_dataset[\"pos\"] = test_dataset[\"document\"].apply(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0215befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = [] \n",
    "\n",
    "for line in train_dataset['pos']:\n",
    "    vocab_size.extend(str(line).split())\n",
    "vocab_size = len(set(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782f8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token='<oov>')\n",
    "tokenizer.fit_on_texts(train_dataset['pos'])\n",
    "word_index = tokenizer.word_index\n",
    "vocabulary_inv = tokenizer.index_word\n",
    "\n",
    "# padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_seq = tokenizer.texts_to_sequences(train_dataset['pos'])\n",
    "test_seq = tokenizer.texts_to_sequences(test_dataset['pos'])\n",
    "train_pad = pad_sequences(train_seq, maxlen=40, padding='pre', truncating='pre')\n",
    "test_pad = pad_sequences(test_seq, maxlen=40, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8cd51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "filter_sizes = (2, 3, 4, 5)\n",
    "num_filters = 100\n",
    "dropout = 0.5\n",
    "hidden_dims = 100\n",
    "\n",
    "batch_size = 50\n",
    "num_epochs = 10\n",
    "min_word_count = 1\n",
    "context = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351bafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec, fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be921fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a6556bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = word2vec.Word2Vec.load(\"../DATA/ko.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c5484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_inv.update({0:'pad'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d070986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/j2ttz_bd7d500bsb_zg9212w0000gn/T/ipykernel_64557/2605901587.py:1: DeprecationWarning: Call to deprecated `syn1neg` (Attribute will be removed in 4.0.0, use self.trainables.syn1neg instead).\n",
      "  same_variance = np.var(embedding_model.syn1neg)\n"
     ]
    }
   ],
   "source": [
    "same_variance = np.var(embedding_model.syn1neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730582b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/j2ttz_bd7d500bsb_zg9212w0000gn/T/ipykernel_64557/2823837837.py:1: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  embedding_weights = {key: embedding_model[word] if word in embedding_model else np.random.uniform(-same_variance, same_variance, embedding_model.vector_size) for key, word in vocabulary_inv.items()}\n",
      "/var/folders/s5/j2ttz_bd7d500bsb_zg9212w0000gn/T/ipykernel_64557/2823837837.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  embedding_weights = {key: embedding_model[word] if word in embedding_model else np.random.uniform(-same_variance, same_variance, embedding_model.vector_size) for key, word in vocabulary_inv.items()}\n"
     ]
    }
   ],
   "source": [
    "embedding_weights = {key: embedding_model[word] if word in embedding_model else np.random.uniform(-same_variance, same_variance, embedding_model.vector_size) for key, word in vocabulary_inv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "733276c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Flatten, Dropout\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54b57e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2021)\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27050568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 40, 200])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional block\n",
    "input_shape=(40, )\n",
    "conv_blocks = []\n",
    "\n",
    "model_input = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "z = keras.layers.Embedding(len(word_index)+1, embedding_dim, input_length=len(train_dataset['label']), name=\"embedding\")(model_input)\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84658b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sz in filter_sizes:\n",
    "    conv = keras.layers.Conv1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"Same\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = keras.layers.MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = keras.layers.Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "    \n",
    "z = keras.layers.Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "z = keras.layers.Dense(512, activation=\"relu\")(z)\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "z = keras.layers.Dense(256, activation=\"relu\")(z)\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "# z = keras.layers.Dense(128, activation=\"relu\")(z)\n",
    "# z = keras.layers.Dropout(dropout)(z)\n",
    "model_output = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = keras.Model(model_input, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b2431b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e103fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 200)      9284600     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 40, 200)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 40, 100)      40100       dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 40, 100)      60100       dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 40, 100)      80100       dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 40, 100)      100100      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 20, 100)      0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 20, 100)      0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 20, 100)      0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 20, 100)      0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 2000)         0           max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 2000)         0           max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 2000)         0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 2000)         0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8000)         0           flatten_20[0][0]                 \n",
      "                                                                 flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 8000)         0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 512)          4096512     dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 512)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 256)          131328      dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 256)          0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            257         dropout_25[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 13,793,097\n",
      "Trainable params: 13,793,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2412a29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with word2vec weights, shape (46423, 200)\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([v for v in embedding_weights.values()])\n",
    "print(\"Initializing embedding layer with word2vec weights, shape\", weights.shape)\n",
    "embedding_layer = model.get_layer(\"embedding\")\n",
    "embedding_layer.set_weights([weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6aea61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n",
      "300/300 - 84s - loss: 0.7046 - accuracy: 0.5620 - val_loss: 0.5666 - val_accuracy: 0.7205\n",
      "Epoch 2/23\n",
      "300/300 - 81s - loss: 0.5448 - accuracy: 0.7236 - val_loss: 0.4799 - val_accuracy: 0.7969\n",
      "Epoch 3/23\n",
      "300/300 - 83s - loss: 0.4667 - accuracy: 0.7800 - val_loss: 0.4603 - val_accuracy: 0.8197\n",
      "Epoch 4/23\n",
      "300/300 - 83s - loss: 0.4289 - accuracy: 0.8041 - val_loss: 0.4247 - val_accuracy: 0.8282\n",
      "Epoch 5/23\n",
      "300/300 - 84s - loss: 0.4084 - accuracy: 0.8173 - val_loss: 0.4252 - val_accuracy: 0.8336\n",
      "Epoch 6/23\n",
      "300/300 - 84s - loss: 0.3914 - accuracy: 0.8268 - val_loss: 0.4066 - val_accuracy: 0.8370\n",
      "Epoch 7/23\n",
      "300/300 - 81s - loss: 0.3787 - accuracy: 0.8342 - val_loss: 0.4007 - val_accuracy: 0.8411\n",
      "Epoch 8/23\n",
      "300/300 - 83s - loss: 0.3674 - accuracy: 0.8405 - val_loss: 0.3940 - val_accuracy: 0.8454\n",
      "Epoch 9/23\n",
      "300/300 - 82s - loss: 0.3579 - accuracy: 0.8455 - val_loss: 0.3929 - val_accuracy: 0.8458\n",
      "Epoch 10/23\n",
      "300/300 - 81s - loss: 0.3483 - accuracy: 0.8504 - val_loss: 0.3727 - val_accuracy: 0.8479\n",
      "Epoch 11/23\n",
      "300/300 - 77s - loss: 0.3413 - accuracy: 0.8544 - val_loss: 0.3618 - val_accuracy: 0.8493\n",
      "Epoch 12/23\n",
      "300/300 - 75s - loss: 0.3355 - accuracy: 0.8575 - val_loss: 0.3648 - val_accuracy: 0.8517\n",
      "Epoch 13/23\n",
      "300/300 - 75s - loss: 0.3303 - accuracy: 0.8604 - val_loss: 0.3649 - val_accuracy: 0.8512\n",
      "Epoch 14/23\n",
      "300/300 - 75s - loss: 0.3221 - accuracy: 0.8641 - val_loss: 0.3558 - val_accuracy: 0.8525\n",
      "Epoch 15/23\n",
      "300/300 - 75s - loss: 0.3164 - accuracy: 0.8664 - val_loss: 0.3501 - val_accuracy: 0.8537\n",
      "Epoch 16/23\n",
      "300/300 - 75s - loss: 0.3107 - accuracy: 0.8704 - val_loss: 0.3539 - val_accuracy: 0.8541\n",
      "Epoch 17/23\n",
      "300/300 - 75s - loss: 0.3058 - accuracy: 0.8727 - val_loss: 0.3513 - val_accuracy: 0.8527\n",
      "Epoch 18/23\n",
      "300/300 - 75s - loss: 0.2996 - accuracy: 0.8746 - val_loss: 0.3515 - val_accuracy: 0.8540\n",
      "Epoch 19/23\n",
      "300/300 - 75s - loss: 0.2963 - accuracy: 0.8768 - val_loss: 0.3539 - val_accuracy: 0.8539\n",
      "Epoch 20/23\n",
      "300/300 - 75s - loss: 0.2929 - accuracy: 0.8799 - val_loss: 0.3464 - val_accuracy: 0.8533\n",
      "Epoch 21/23\n",
      "300/300 - 76s - loss: 0.2883 - accuracy: 0.8800 - val_loss: 0.3455 - val_accuracy: 0.8531\n",
      "Epoch 22/23\n",
      "300/300 - 83s - loss: 0.2844 - accuracy: 0.8821 - val_loss: 0.3477 - val_accuracy: 0.8551\n",
      "Epoch 23/23\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_pad, train_dataset['label'], batch_size=500, epochs=23, validation_data=(test_pad, test_dataset['label']),verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
