{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a79557f1",
   "metadata": {},
   "source": [
    "# Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9cddf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd26ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 데이터 가져오기\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6084ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터의 shape 바꿔주기\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "                                \n",
    "# 정규화\n",
    "train_images, test_images = train_images/255.0, test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64f9918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "valid_images, test_images, valid_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f1a0c",
   "metadata": {},
   "source": [
    "## sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef2a1999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-23 12:04:18.767584: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-07-23 12:04:18.778946: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd6e5b575d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-07-23 12:04:18.778958: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "# 모델 만들기\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1), padding='Same'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu', padding='Same'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu', padding='Same'))\n",
    "\n",
    "# 순서대로 일렬로 만들기\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# 신경망 학습\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9c498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 257,162\n",
      "Trainable params: 257,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4e8c3f",
   "metadata": {},
   "source": [
    "## functional api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adbb4e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 모델 생성하기\n",
    "inputs = layers.Input(shape=(28,28,1))\n",
    "conv1 = layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu)(inputs)\n",
    "pool1 = layers.MaxPooling2D(padding='same')(conv1)\n",
    "conv2 = layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu)(pool1)\n",
    "pool2 = layers.MaxPooling2D(padding='same')(conv2)\n",
    "conv3 = layers.Conv2D(128, (3,3), padding='same', activation=tf.nn.relu)(pool2)\n",
    "pool3 = layers.MaxPooling2D(padding='same')(conv3)\n",
    "pool3_flat = layers.Flatten()(pool3)\n",
    "dense4 = layers.Dense(256, activation=tf.nn.relu)(pool3_flat)\n",
    "drop4 = layers.Dropout(rate=0.2)(dense4)\n",
    "logits = layers.Dense(units=10, activation='softmax')(drop4)\n",
    "model = Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45283a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 619,786\n",
      "Trainable params: 619,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c3afe0",
   "metadata": {},
   "source": [
    "## 모델 클래스화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c1f310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 정규화\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class ConvBNRelu(Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=(1,1), padding=\"same\"):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.conv = layers.Conv2D(filters, kernel_size=kernel_size,\n",
    "                                  strides=strides, padding=padding,\n",
    "                                  kernel_initializer='glorot_normal')\n",
    "        self.batchnorm = BatchNormalization()\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        layer = self.conv(inputs)\n",
    "        layer = self.batchnorm(layer)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        \n",
    "        return layer\n",
    "    \n",
    "class DenseBNRelu(Model):\n",
    "    def __init__(self, units):\n",
    "        super(DenseBNRelu, self).__init__()\n",
    "        self.dense = layers.Dense(units=units, kernel_initializer='glorot_normal')\n",
    "        self.batchnorm = BatchNormalization()\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        layer = self.dense(inputs)\n",
    "        layer = self.batchnorm(layer)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda99a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNistModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MNistModel, self).__init__()\n",
    "        self.conv1 = ConvBNRelu(32, (3,3), padding='same')\n",
    "        self.pool1 = layers.MaxPooling2D(padding='same')\n",
    "        self.conv2 = ConvBNRelu(64, (3,3), padding='same')\n",
    "        self.pool2 = layers.MaxPooling2D(padding='same')\n",
    "        self.conv3 = ConvBNRelu(128, (3,3), padding='same')\n",
    "        self.pool3 = layers.MaxPooling2D(padding='same')\n",
    "        self.pool3_flat = layers.Flatten()\n",
    "        self.dense4 = DenseBNRelu(256)\n",
    "        self.drop4 = layers.Dropout(rate=0.2)\n",
    "        self.dense5 = layers.Dense(units=10, activation='softmax', kernel_initializer='glorot_normal')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.pool1(net)\n",
    "        net = self.conv2(net)\n",
    "        net = self.pool2(net)\n",
    "        net = self.conv3(net)\n",
    "        net = self.pool3(net)\n",
    "        net = self.pool3_flat(net)\n",
    "        net = self.dense4(net)\n",
    "        net = self.drop4(net)\n",
    "        output = self.dense5(net)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04e721a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"m_nist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_bn_relu (ConvBNRelu)    (None, 28, 28, 32)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_bn_relu_1 (ConvBNRelu)  (None, 14, 14, 64)        18752     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_bn_relu_2 (ConvBNRelu)  (None, 7, 7, 128)         74368     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_bn_relu (DenseBNRelu)  (None, 256)               525568    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 621,706\n",
      "Trainable params: 620,746\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MNistModel()\n",
    "model(layers.Input(shape=(28,28,1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d0c78",
   "metadata": {},
   "source": [
    "## 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "702544f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earlystopping을 해보자!\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "MODEL_SAVE_FOLDER_PATH = '../../DATA'\n",
    "model_file_path = f'{MODEL_SAVE_FOLDER_PATH}/mnist-{{epoch:d}}-{{val_loss:.5f}}-{{val_accuracy:.5f}}.hdf5'\n",
    "\n",
    "# 체크 포인트 지정\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_file_path, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "# 언제 멈출 것인가? patience(역전되었을 때도 얼마나 참아줄 것인지 정해주는 것)\n",
    "cb_early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0644a420",
   "metadata": {},
   "source": [
    "##### hdf5 저장문제\n",
    "##### - tensorflow 버전 문제로 subclass 했던 것은 모델 저장 안 될 수 있음\n",
    "##### - 저장을 위해 functional api로 돌리거나, tensorflow 2.2로 다운 그래이드할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed5521ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9717\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.11587, saving model to ../../DATA/mnist-1-5.56499-0.11587.hdf5\n",
      "300/300 [==============================] - 29s 96ms/step - loss: 0.0973 - accuracy: 0.9717 - val_loss: 5.5650 - val_accuracy: 0.1159\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9910\n",
      "Epoch 00002: val_accuracy improved from 0.11587 to 0.97000, saving model to ../../DATA/mnist-2-0.09093-0.97000.hdf5\n",
      "300/300 [==============================] - 30s 100ms/step - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.0909 - val_accuracy: 0.9700\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9934\n",
      "Epoch 00003: val_accuracy improved from 0.97000 to 0.99075, saving model to ../../DATA/mnist-3-0.03048-0.99075.hdf5\n",
      "300/300 [==============================] - 31s 103ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0305 - val_accuracy: 0.9908\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9961\n",
      "Epoch 00004: val_accuracy did not improve from 0.99075\n",
      "300/300 [==============================] - 31s 105ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0412 - val_accuracy: 0.9865\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9971\n",
      "Epoch 00005: val_accuracy did not improve from 0.99075\n",
      "300/300 [==============================] - 31s 103ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0397 - val_accuracy: 0.9880\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 00006: val_accuracy did not improve from 0.99075\n",
      "300/300 [==============================] - 31s 103ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0333 - val_accuracy: 0.9901\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9975\n",
      "Epoch 00007: val_accuracy did not improve from 0.99075\n",
      "300/300 [==============================] - 31s 104ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0341 - val_accuracy: 0.9900\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9977\n",
      "Epoch 00008: val_accuracy did not improve from 0.99075\n",
      "300/300 [==============================] - 31s 103ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0420 - val_accuracy: 0.9875\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9981\n",
      "Epoch 00009: val_accuracy improved from 0.99075 to 0.99125, saving model to ../../DATA/mnist-9-0.02904-0.99125.hdf5\n",
      "300/300 [==============================] - 31s 104ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0290 - val_accuracy: 0.9912\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 00010: val_accuracy did not improve from 0.99125\n",
      "300/300 [==============================] - 31s 105ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0451 - val_accuracy: 0.9885\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 00011: val_accuracy improved from 0.99125 to 0.99325, saving model to ../../DATA/mnist-11-0.02108-0.99325.hdf5\n",
      "300/300 [==============================] - 31s 103ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0211 - val_accuracy: 0.9933\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 00012: val_accuracy improved from 0.99325 to 0.99413, saving model to ../../DATA/mnist-12-0.02018-0.99413.hdf5\n",
      "300/300 [==============================] - 31s 103ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0202 - val_accuracy: 0.9941\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 7.2047e-04 - accuracy: 0.9999\n",
      "Epoch 00013: val_accuracy improved from 0.99413 to 0.99462, saving model to ../../DATA/mnist-13-0.02062-0.99462.hdf5\n",
      "300/300 [==============================] - 31s 104ms/step - loss: 7.2047e-04 - accuracy: 0.9999 - val_loss: 0.0206 - val_accuracy: 0.9946\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 3.5644e-04 - accuracy: 1.0000\n",
      "Epoch 00014: val_accuracy did not improve from 0.99462\n",
      "300/300 [==============================] - 31s 103ms/step - loss: 3.5644e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9937\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.6274e-04 - accuracy: 1.0000\n",
      "Epoch 00015: val_accuracy did not improve from 0.99462\n",
      "300/300 [==============================] - 31s 105ms/step - loss: 2.6274e-04 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9944\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.3395e-04 - accuracy: 1.0000\n",
      "Epoch 00016: val_accuracy improved from 0.99462 to 0.99488, saving model to ../../DATA/mnist-16-0.02095-0.99488.hdf5\n",
      "300/300 [==============================] - 31s 105ms/step - loss: 2.3395e-04 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9949\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.3909e-04 - accuracy: 1.0000\n",
      "Epoch 00017: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 31s 105ms/step - loss: 2.3909e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9941\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.6326e-04 - accuracy: 1.0000\n",
      "Epoch 00018: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 31s 104ms/step - loss: 2.6326e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9940\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9981\n",
      "Epoch 00019: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 31s 104ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0340 - val_accuracy: 0.9912\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 00020: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 31s 105ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0316 - val_accuracy: 0.9912\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 9.5970e-04 - accuracy: 0.9998\n",
      "Epoch 00021: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 31s 104ms/step - loss: 9.5970e-04 - accuracy: 0.9998 - val_loss: 0.0228 - val_accuracy: 0.9939\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0238 - accuracy: 0.9930\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "# ExponentialDecay? 훈련 과정이 진행됨에 따라 lr을 조금씩(지수함수따라서 줄임) 낮춰가기 위한 방법\n",
    "# (학습률, 스탭크기, 줄이는 비율)\n",
    "lr_decay = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate, train_images.shape[0]/batch_size*5, 0.5, staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decay)\n",
    "\n",
    "# 모델 컴파일 하기\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# validation 추가 및 hist에 저장하여 그래프 그리는 재료로 사용하기\n",
    "hist = model.fit(train_images, train_labels, \n",
    "                 validation_data = (valid_images, valid_labels), \n",
    "                 epochs=100,\n",
    "                batch_size=200,\n",
    "                callbacks=[cb_checkpoint, cb_early_stopping])\n",
    "\n",
    "# 모델 테스트하여 loss 및 acc 저장하기\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9218987",
   "metadata": {},
   "source": [
    "모델 불러오기\n",
    "model.load_weights(경로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4730d7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb6dc6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display(hist):\n",
    "    fig, loss_ax = plt.subplots()\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train_loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='valid_loss')\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train_accuracy')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='valid_accuracy')\n",
    "    acc_ax.set_xlabel('epoch')\n",
    "    acc_ax.set_ylabel('accuracy')\n",
    "    acc_ax.legend(loc='upper right', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "display(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91daeb35",
   "metadata": {},
   "source": [
    "## pretrain된 자료 가져오기 (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "066a8a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "# mnist 데이터 가져오기\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e101f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VVG16에 맞춰 3차원으로 만들기\n",
    "import numpy as np\n",
    "\n",
    "# 3차원 만들기 위해 1차원 배열로 바꾼 후\n",
    "train_images = train_images.reshape(-1, 784).astype('float32')\n",
    "test_images = test_images.reshape(-1, 784).astype('float32')\n",
    "# 3배로 증식해서\n",
    "train_images = np.dstack([train_images]*3)\n",
    "test_images = np.dstack([test_images]*3)\n",
    "# 3차원으로 다시 형태 바꿔주기\n",
    "train_images = train_images.reshape(-1, 28, 28, 3)\n",
    "test_images = test_images.reshape(-1, 28, 28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fd68449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 48, 48, 3), (10000, 48, 48, 3))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "# 이미지 확대하기\n",
    "train_images = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48, 48))) for im in train_images])\n",
    "test_images = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48, 48))) for im in test_images])  \n",
    "\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8c4f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화\n",
    "train_images = train_images/255.\n",
    "test_images = test_images/255.\n",
    "\n",
    "valid_images, test_images, valid_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f9f56aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc8aa917",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = {layer.name : layer for layer in vgg_model.layers}\n",
    "x = layer_dict['block2_pool'].output\n",
    "\n",
    "x = ConvBNRelu(filters=64, kernel_size=(3, 3))(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = DenseBNRelu(256)(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10689151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x7fd6fbf478b0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model = Model(inputs=vgg_model.input, outputs=x)\n",
    "custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3630dab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9777\n",
      "Epoch 00001: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 107s 357ms/step - loss: 0.0760 - accuracy: 0.9777 - val_loss: 0.0365 - val_accuracy: 0.9879\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9928\n",
      "Epoch 00002: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 108s 361ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0225 - val_accuracy: 0.9929\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9953\n",
      "Epoch 00003: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 106s 353ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.0231 - val_accuracy: 0.9925\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9965\n",
      "Epoch 00004: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 106s 355ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0205 - val_accuracy: 0.9927\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 00005: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 109s 365ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0212 - val_accuracy: 0.9931\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9981\n",
      "Epoch 00006: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 109s 362ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.0266 - val_accuracy: 0.9923\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 00007: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 107s 357ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0177 - val_accuracy: 0.9941\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 00008: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 110s 366ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0270 - val_accuracy: 0.9910\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9988\n",
      "Epoch 00009: val_accuracy did not improve from 0.99488\n",
      "300/300 [==============================] - 106s 353ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0468 - val_accuracy: 0.9862\n",
      "Epoch 10/100\n",
      " 60/300 [=====>........................] - ETA: 1:18 - loss: 0.0038 - accuracy: 0.9990"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s5/j2ttz_bd7d500bsb_zg9212w0000gn/T/ipykernel_23602/3094328178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# validation 추가 및 hist에 저장하여 그래프 그리는 재료로 사용하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m hist = custom_model.fit(train_images, train_labels, \n\u001b[0m\u001b[1;32m     19\u001b[0m                  \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlppython/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlppython/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlppython/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlppython/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlppython/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlppython/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlppython/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlppython/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlppython/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 커스텀 모델 프리징 (학습 안함)\n",
    "for layer in custom_model.layers[:7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "# ExponentialDecay? 훈련 과정이 진행됨에 따라 lr을 조금씩(지수함수따라서 줄임) 낮춰가기 위한 방법\n",
    "# (학습률, 스탭크기, 줄이는 비율)\n",
    "lr_decay = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate, train_images.shape[0]/batch_size*5, 0.5, staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decay)\n",
    "\n",
    "# 모델 컴파일 하기\n",
    "custom_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# validation 추가 및 hist에 저장하여 그래프 그리는 재료로 사용하기\n",
    "hist = custom_model.fit(train_images, train_labels, \n",
    "                 validation_data = (valid_images, valid_labels), \n",
    "                 epochs=100,\n",
    "                batch_size=200,\n",
    "                callbacks=[cb_checkpoint, cb_early_stopping])\n",
    "\n",
    "#### 시간 오래걸린다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.load_weights()\n",
    "test_loss, test_accuracy = custom_model.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
