{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survivor Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rc(\"font\", family=\"AppleGothic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data와 Test data 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pclass: 선실 등급\n",
    "- sibsp: 형제자매\n",
    "- Parch: 부모, 자식\n",
    "- Fare: 티켓 요금\n",
    "- cabin: 선실\n",
    "- Embarked: 승선지\n",
    "##### info()와 describe() 사용하여 데이터 먼저 훑어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = pd.read_csv(\"./titanic/titanic_train.csv\", header=0, sep=\",\")\n",
    "titanic_test = pd.read_csv(\"./titanic/titanic_test.csv\", header=0, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계적 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 성별에 따른 생존 결과\n",
    "# print(titanic_train.groupby([\"Sex\",\"Survived\"])[\"Survived\"].count())\n",
    "# sns.barplot(x=\"Sex\", y=\"Survived\", data=titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 선실 등급에 따른 생존 결과\n",
    "# print(titanic_train.groupby([\"Pclass\",\"Survived\"])[\"Survived\"].count())\n",
    "# sns.barplot(x=\"Pclass\", y=\"Survived\", data=titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 나이 등급에 따른 생존 결과\n",
    "# group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young adult', 'Adult', 'Elder']\n",
    "# titanic_train[\"Age_Range\"]=titanic_train[\"Age\"].apply(lambda x: \"Baby\" if x<=5 else \"Child\" if x<=12 else \"Teenager\" if x<=18 else \"Student\" if x<=25 else \"Young adult\" if x<=35 else \"Adult\" if x<=60 else \"Elderly\" if x>=61 else \"Unknown\")\n",
    "# plt.figure(figsize=(10,6))\n",
    "# print(titanic_train.groupby([\"Age_Range\",\"Survived\"])[\"Survived\"].count())\n",
    "# sns.barplot(x=\"Age_Range\", y=\"Survived\", hue=\"Sex\", data=titanic_train, order=group_names)\n",
    "# titanic_train.drop(\"Age_Range\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 형제자매 유무에 따른 생존 결과\n",
    "# print(titanic_train.groupby([\"SibSp\",\"Survived\"])[\"Survived\"].count())\n",
    "# sns.barplot(x=\"SibSp\", y=\"Survived\", data=titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 부모자식 관계에 따른 생존 결과\n",
    "# print(titanic_train.groupby([\"Parch\",\"Survived\"])[\"Survived\"].count())\n",
    "# sns.barplot(x=\"Parch\", y=\"Survived\", data=titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 티켓 요금에 따른 생존 결과\n",
    "# ticket_fare = [\"0~19\", \"20~39\", \"40~59\", \"고가의 티켓\"]\n",
    "# titanic_train[\"Ticket_fare\"]=titanic_train[\"Fare\"].apply(lambda x: \"0~19\" if x<20 else \"20~39\" if x<40 else \"40~59\" if x<60 else \"고가의 티켓\")\n",
    "# print(titanic_train.groupby([\"Ticket_fare\",\"Survived\"])[\"Survived\"].count())\n",
    "# sns.barplot(x=\"Ticket_fare\", y=\"Survived\", data=titanic_train, order=ticket_fare)\n",
    "# titanic_train.drop(\"Ticket_fare\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 선실에 따른 생존 결과\n",
    "# cabin = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"N\", \"T\"]\n",
    "# print(titanic_train.groupby([\"Cabin\",\"Survived\"])[\"Survived\"].count())\n",
    "# sns.barplot(x=\"Cabin\", y=\"Survived\", data=titanic_train, order=cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 승선지에 따른 생존 결과\n",
    "# print(titanic_train.groupby([\"Embarked\",\"Survived\"])[\"Survived\"].count())\n",
    "# sns.barplot(x=\"Embarked\", y=\"Survived\", data=titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 빈부격차에 따른 생존 \n",
    "# sns.barplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=titanic_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유용한 함수 생성 (결측치 제거, 열 정제, 인코딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n",
    "    df[\"Cabin\"].fillna(\"N\", inplace=True)\n",
    "    df[\"Embarked\"].fillna(\"N\", inplace=True)\n",
    "    df[\"Fare\"].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# ML 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행\n",
    "def format_features(df):\n",
    "    df[\"Cabin\"] = df[\"Cabin\"].str[:1]\n",
    "    features = [\"Cabin\",\"Sex\",\"Embarked\"]\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 데이터 전처리 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 원본 데이터 재로딩하고, 피처 데이터 세트와 레이블 데이터 세트 추출\n",
    "titanic_df = pd.read_csv(\"./titanic/titanic_train.csv\")\n",
    "y_titanic_df = titanic_df[\"Survived\"]\n",
    "x_titanic_df = titanic_df.drop(\"Survived\", axis = 1)\n",
    "\n",
    "x_titanic_df = transform_features(x_titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다양한 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTresCalssifier 0.7877\n",
      "RandomForestClassifier 0.8547\n",
      "LogisticRegression 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryleyun/opt/anaconda3/envs/nlppython/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_titanic_df, y_titanic_df, test_size = 0.2, random_state=11)\n",
    "\n",
    "\n",
    "# 세 개 모델에 객체 생성\n",
    "titanic_DT = DecisionTreeClassifier(random_state=11)\n",
    "titanic_RF = RandomForestClassifier(random_state=11)\n",
    "titanic_LR = LogisticRegression()\n",
    "\n",
    "\n",
    "# DecisionTreeClassifier\n",
    "titanic_DT.fit(x_train, y_train)\n",
    "pred_dt = titanic_DT.predict(x_test)\n",
    "print(\"DecisionTresCalssifier\", np.round(accuracy_score(y_test, pred_dt), 4))\n",
    "\n",
    "# RandomForestClassifier\n",
    "titanic_RF.fit(x_train, y_train)\n",
    "pred_rf = titanic_RF.predict(x_test)\n",
    "print(\"RandomForestClassifier\", np.round(accuracy_score(y_test, pred_rf), 4))\n",
    "\n",
    "# LogisticRegression\n",
    "titanic_LR.fit(x_train, y_train)\n",
    "pred_lr = titanic_LR.predict(x_test)\n",
    "print(\"LogisticRegression\", np.round(accuracy_score(y_test, pred_lr), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -> RandomForestClassifier가 높음. Ensemble 많이 쓰는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의사 결정 나무 + K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#0 교차 검증 정확도: 0.7333\n",
      "\n",
      "#1 교차 검증 정확도: 0.7753\n",
      "\n",
      "#2 교차 검증 정확도: 0.7416\n",
      "\n",
      "#3 교차 검증 정확도: 0.7528\n",
      "\n",
      "#4 교차 검증 정확도: 0.809\n",
      "\n",
      "#5 교차 검증 정확도: 0.809\n",
      "\n",
      "#6 교차 검증 정확도: 0.809\n",
      "\n",
      "#7 교차 검증 정확도: 0.764\n",
      "\n",
      "#8 교차 검증 정확도: 0.8652\n",
      "\n",
      "#9 교차 검증 정확도: 0.8427\n",
      "\n",
      "## 평균 검증 정확도 :  0.7902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# 의사 결정 나무 객체 생성\n",
    "titanic_DT = DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "# KFold 지정\n",
    "kfold = KFold(n_splits = 5)\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "\n",
    "# 함수 생성\n",
    "def exec_kfold(clf, folds=5):\n",
    "    kfold = KFold(n_splits = folds)\n",
    "    scores = []\n",
    "\n",
    "# train, test 데이터 k_fold에 따라 나누기\n",
    "    for iter_count, (train_index, test_index) in enumerate(kfold.split(x_titanic_df)):\n",
    "\n",
    "        x_train, x_test = x_titanic_df.iloc[train_index], x_titanic_df.iloc[test_index]\n",
    "        y_train, y_test = y_titanic_df[train_index], y_titanic_df[test_index]\n",
    "\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "        print(\"\\n#{0} 교차 검증 정확도: {1}\".format(iter_count, accuracy))\n",
    "    \n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"\\n## 평균 검증 정확도 : \", round(mean_score, 4))\n",
    "    \n",
    "    \n",
    "exec_kfold(titanic_DT, folds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의사 결정 나무 + StratifiedKfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도: 0.743, 학습데이터 크기: 712, 검증데이터 크기: 179\n",
      "\n",
      "#2 교차 검증 정확도: 0.7753, 학습데이터 크기: 713, 검증데이터 크기: 178\n",
      "\n",
      "#3 교차 검증 정확도: 0.7921, 학습데이터 크기: 713, 검증데이터 크기: 178\n",
      "\n",
      "#4 교차 검증 정확도: 0.7865, 학습데이터 크기: 713, 검증데이터 크기: 178\n",
      "\n",
      "#5 교차 검증 정확도: 0.8427, 학습데이터 크기: 713, 검증데이터 크기: 178\n",
      "\n",
      "## 평균 검증 정확도 :  0.78792\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# 의사 결정 나무 객체 생성\n",
    "titanic_DT = DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "# KFold 지정\n",
    "skfold = StratifiedKFold(n_splits = 5)\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "# train, test 데이터 StratifiedKFold에 따라 나누기, y값 넣기\n",
    "for train_index, test_index in skfold.split(x_titanic_df, y_titanic_df):\n",
    "    \n",
    "    x_train, x_test = x_titanic_df.iloc[train_index], x_titanic_df.iloc[test_index]\n",
    "    y_train, y_test = y_titanic_df[train_index], y_titanic_df[test_index]\n",
    "    \n",
    "    \n",
    "    titanic_DT.fit(x_train, y_train)\n",
    "    pred = titanic_DT.predict(x_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_test.shape[0]\n",
    "    \n",
    "    print(\"\\n#{0} 교차 검증 정확도: {1}, 학습데이터 크기: {2}, 검증데이터 크기: {3}\".format(n_iter, accuracy, train_size, test_size))\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "    \n",
    "print(\"\\n## 평균 검증 정확도 : \", np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의사 결정 나무 + cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.743  0.7753 0.7921 0.7865 0.8427]\n",
      "평균 검증 정확도: 0.7879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "scores = cross_val_score(titanic_DT, x_titanic_df, y_titanic_df, scoring=\"accuracy\", cv=5)\n",
    "\n",
    "print('교차 검증별 정확도:', np.round(scores, 4))\n",
    "print('평균 검증 정확도:', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이퍼 파라미터:  {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.7992\n",
      "테스트 세트에서의 DecisionTreeClassifier 정확도: 0.8715\n",
      "테스트 세트에서의 DecisionTreeClassifier 정밀도: 0.8393\n",
      "테스트 세트에서의 DecisionTreeClassifier 재현율: 0.7705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "parameters = {\"max_depth\":[2,3,5,10], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,5,8]}\n",
    "\n",
    "grid_dtree = GridSearchCV(titanic_DT, param_grid=parameters, scoring=\"accuracy\", cv = 5)\n",
    "\n",
    "grid_dtree.fit(x_train, y_train)\n",
    "\n",
    "print(\"GridSearchCV 최적 하이퍼 파라미터: \", grid_dtree.best_params_)\n",
    "print(\"GridSearchCV 최고 정확도: {0:.4f}\".format(grid_dtree.best_score_))\n",
    "best_dclf = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 estimator로 예측 및 평가 수행\n",
    "dpredictions = best_dclf.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, dpredictions)\n",
    "precision = precision_score(y_test, dpredictions)\n",
    "recall = recall_score(y_test, dpredictions)\n",
    "\n",
    "print(\"테스트 세트에서의 DecisionTreeClassifier 정확도: {0:.4f}\".format(accuracy))\n",
    "print(\"테스트 세트에서의 DecisionTreeClassifier 정밀도: {0:.4f}\".format(precision))\n",
    "print(\"테스트 세트에서의 DecisionTreeClassifier 재현율: {0:.4f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정확도(accuracy): TP+TN/TP+FP+FN+TN (얼마나 정답을 맞춰는가) \n",
    "- 정밀도(precision): TP/TP+FP (모델이 True라고 말한 것 중 정답이 몇개인가)\n",
    "- 재현율(recall): TP?TP+FN (원래 값이 True인 것에 대해 모델이 얼마나 True라고 재현했는가)\n",
    "- 정밀도와 재현율의 중간값(F1 Score): 2*(precision*recall)/(precision+recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
