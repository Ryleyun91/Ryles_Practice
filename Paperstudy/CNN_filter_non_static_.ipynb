{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d35bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import preprocessing \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24eddb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_dataset = pd.read_csv('../DATA/train_spacing.csv')\n",
    "test_dataset = pd.read_csv('../DATA/test_spacing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812e0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "289719d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 42.5 ms, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def pos(x):\n",
    "    try:\n",
    "        text = ''\n",
    "        for word, pos in mecab.pos(str(x)):\n",
    "            if pos[0] not in ['J','I','E']:\n",
    "                if type(re.search(\"\\W+|[0-9]\", word))!=re.Match: \n",
    "                    # and len(word)!=1:\n",
    "                    text+=\" \"+word\n",
    "        return text.strip()\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "train_dataset[\"pos\"] = train_dataset[\"document\"].apply(pos)\n",
    "test_dataset[\"pos\"] = test_dataset[\"document\"].apply(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0215befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = [] \n",
    "\n",
    "for line in train_dataset['pos']:\n",
    "    vocab_size.extend(str(line).split())\n",
    "vocab_size = len(set(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782f8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token='<oov>')\n",
    "tokenizer.fit_on_texts(train_dataset['pos'])\n",
    "word_index = tokenizer.word_index\n",
    "vocabulary_inv = tokenizer.index_word\n",
    "\n",
    "# padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_seq = tokenizer.texts_to_sequences(train_dataset['pos'])\n",
    "test_seq = tokenizer.texts_to_sequences(test_dataset['pos'])\n",
    "train_pad = pad_sequences(train_seq, maxlen=40, padding='pre', truncating='pre')\n",
    "test_pad = pad_sequences(test_seq, maxlen=40, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8cd51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "filter_sizes = (2, 3, 4, 5)\n",
    "num_filters = 100\n",
    "dropout = 0.5\n",
    "hidden_dims = 100\n",
    "\n",
    "batch_size = 50\n",
    "num_epochs = 10\n",
    "min_word_count = 1\n",
    "context = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351bafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec, fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be921fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a6556bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = word2vec.Word2Vec.load(\"../DATA/ko.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c5484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_inv.update({0:'pad'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d070986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/j2ttz_bd7d500bsb_zg9212w0000gn/T/ipykernel_59060/2605901587.py:1: DeprecationWarning: Call to deprecated `syn1neg` (Attribute will be removed in 4.0.0, use self.trainables.syn1neg instead).\n",
      "  same_variance = np.var(embedding_model.syn1neg)\n"
     ]
    }
   ],
   "source": [
    "same_variance = np.var(embedding_model.syn1neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730582b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/j2ttz_bd7d500bsb_zg9212w0000gn/T/ipykernel_59060/2823837837.py:1: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  embedding_weights = {key: embedding_model[word] if word in embedding_model else np.random.uniform(-same_variance, same_variance, embedding_model.vector_size) for key, word in vocabulary_inv.items()}\n",
      "/var/folders/s5/j2ttz_bd7d500bsb_zg9212w0000gn/T/ipykernel_59060/2823837837.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  embedding_weights = {key: embedding_model[word] if word in embedding_model else np.random.uniform(-same_variance, same_variance, embedding_model.vector_size) for key, word in vocabulary_inv.items()}\n"
     ]
    }
   ],
   "source": [
    "embedding_weights = {key: embedding_model[word] if word in embedding_model else np.random.uniform(-same_variance, same_variance, embedding_model.vector_size) for key, word in vocabulary_inv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "733276c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Flatten, Dropout\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b57e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2021)\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27050568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-02 02:34:24.642822: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 40, 200])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional block\n",
    "input_shape=(40, )\n",
    "conv_blocks = []\n",
    "\n",
    "model_input = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "z = keras.layers.Embedding(len(word_index)+1, embedding_dim, input_length=len(train_dataset['label']), name=\"embedding\")(model_input)\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84658b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sz in filter_sizes:\n",
    "    conv = keras.layers.Conv1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"Same\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = keras.layers.MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = keras.layers.Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "    \n",
    "z = keras.layers.Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "z = keras.layers.Dense(512, activation=\"relu\")(z)\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "z = keras.layers.Dense(256, activation=\"relu\")(z)\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "z = keras.layers.Dense(128, activation=\"relu\")(z)\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "model_output = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = keras.Model(model_input, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b2431b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e103fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 200)      9284600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 40, 200)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 40, 100)      40100       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 40, 100)      60100       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 40, 100)      80100       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 40, 100)      100100      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 20, 100)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 20, 100)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 20, 100)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 20, 100)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2000)         0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2000)         0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2000)         0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2000)         0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8000)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8000)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          4096512     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,825,865\n",
      "Trainable params: 13,825,865\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2412a29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with word2vec weights, shape (46423, 200)\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([v for v in embedding_weights.values()])\n",
    "print(\"Initializing embedding layer with word2vec weights, shape\", weights.shape)\n",
    "embedding_layer = model.get_layer(\"embedding\")\n",
    "embedding_layer.set_weights([weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6aea61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-02 02:34:32.193622: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "300/300 - 76s - loss: 0.7167 - accuracy: 0.5094 - val_loss: 0.6669 - val_accuracy: 0.5986\n",
      "Epoch 2/22\n",
      "300/300 - 75s - loss: 0.6155 - accuracy: 0.6492 - val_loss: 0.5332 - val_accuracy: 0.7788\n",
      "Epoch 3/22\n",
      "300/300 - 74s - loss: 0.5049 - accuracy: 0.7600 - val_loss: 0.4781 - val_accuracy: 0.8111\n",
      "Epoch 4/22\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_pad, train_dataset['label'], batch_size=500, epochs=22, validation_data=(test_pad, test_dataset['label']),verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
